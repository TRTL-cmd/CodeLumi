```markdown
Date: 2026-01-25
Author: GitHub Copilot (assistant)

Lumi-specific daily log (what I changed and why)

High-level
- Focus: make `Lumi` the single visible persona, ensure renderer can answer from a local canonical KB, and make the environment ESM/TypeScript compatible.
- This log explains the Lumi-focused bits developers or product folks care about: assets, IPC surface, localStorage keys, and privacy posture.

What changed (Lumi-specific)
- Persona/Visuals
  - Hid legacy SVG avatar present in older UI assets so the primary 3D model `assets/models/Lumi.glb` is used at runtime.
  - Kept the GLB loading path and debug logs intact so it's easy to verify rendering works.

- KB persistence & local-first behavior
  - Renderer now merges a canonical KB file provided by the main process at startup. Merge is non-destructive and deduplicates by entry id/q.
  - Save path: canonical file lives in the app `userData` directory and is written by main-process IPC handlers when renderer calls `window.lumi.saveKnowledge(kb)`.
  - Renderer still keeps a copy in `localStorage` under `lumi_kb_v2` for window-local fast access and privacy-first operation.

- IPC / preload surface
  - Preload exposes `window.lumi.loadKnowledge()` and `window.lumi.saveKnowledge()` (and related `lumi-*` handlers). Renderer calls these for canonical sync.
  - No live broadcast (`kb-updated`) implemented yet; merging occurs on startup and on manual save/load actions.

How to validate Lumi-specific behavior
1. Launch the app and open the renderer; confirm only the GLB is displayed (the old pink SVG should be hidden).
2. Open DevTools Console and run:
```js
// load canonical KB and show merged count
window.lumi.loadKnowledge().then(kb => console.log('canonical-kb-entries', (kb||[]).length));
console.log('localStorage lumi_kb_v2 entries', JSON.parse(localStorage.getItem('lumi_kb_v2') || '[]').length);
```
3. Perform a KB save from the UI and confirm the main process file timestamp changes (or that `window.lumi.saveKnowledge()` resolves).

Developer notes & caveats
- The canonical save/load calls are synchronous from the renderer's perspective (they return Promises) but writing occurs in the main process. If multiple windows save at once there is no real-time merge — last-writer-wins and manual reload is needed.
- Decision logic for returning KB-first answers is intentionally conservative and left to be tuned. Do not flip to aggressive KB-first thresholds until you validate on representative queries.

Next Lumi-focused tasks
1. Add `kb-updated` broadcast in `src/main.ts` and handle it in `src/preload.ts` so renderers automatically merge updates.
2. Add a small UI toggle that asks the user to opt-into saving to the canonical KB (privacy control).
3. Add a visual indicator when answers come from KB vs remote LLM (helps QA and trust).

If you want, I can implement (1) now and wire the renderer to automatically merge updates.

End of Lumi log for 2026-01-25.

## Full Lumi-focused technical log — 2026-01-25

Author: GitHub Copilot (assistant)

Summary
- Implemented end-to-end learning capture: assistant replies are now persisted as candidate entries and merged (conservatively) into the canonical KB.
- Added renderer-visible learning UX: `Mark helpful` button, short learning toast (3s), and a small metrics surface.
- Stabilized TypeScript/Node ESM imports (`.js` specifiers) and fixed a TS diagnostic caused by `fs` usage.

Detailed changes (Lumi-specific)

- Persona / Visuals
  - Hid the legacy SVG avatar in renderer assets and made `assets/models/Lumi.glb` the authoritative persona render path.
  - Left detailed GLB loading logs in place to help QA verify rendering on startup and asset load errors.

- Local KB persistence and privacy posture
  - Renderer merges the canonical KB from the main process on startup into `localStorage` under `lumi_kb_v2` for local-first queries.
  - The canonical file is written by the main process into the app `userData` directory; renderer calls are via `window.lumi.saveKnowledge()` and `window.lumi.loadKnowledge()`.
  - Current merge policy is conservative: exact-`input` dedupe only; paraphrase/fuzzy dedupe not yet implemented.

- Learning capture and acceptance flows
  - `Mark helpful` (renderer): user-initiated signal that sends `{q,a,confidence,source:'user_mark_helpful'}` to main via `window.lumi.logAssistant()`.
  - `lumi-log-assistant` (main): records an audit entry in `training/training.jsonl` and conditionally merges into `training/lumi_knowledge.json`.
  - Emitted `lumi-learning-event` to renderer on successful merge so the UI can show confirmation (toast) and metrics update.

- Quality controls and validators
  - `CandidateValidator` enforces minimal answer length and basic safety heuristics (PII filter and non-empty responses) prior to merge.
  - Candidate extraction can run from detected signals or direct assistant output; extraction heuristics are intentionally lightweight so we can iterate.

- Metrics and observability
  - `lumi-metrics` IPC computes `totalKB`, `eventsToday`, and `eventsPerHour` from `training/lumi_knowledge.json` and `training/training.jsonl`.
  - Renderer polls metrics every 60s and shows them in a compact panel; `window.lumi.getMetrics()` is exposed for ad-hoc queries.

Where I stopped tonight (what remains paused)

- Deduplication: fuzzy/embedding-based deduplication was not implemented. Current merges are exact-match only. Risk: duplicates and paraphrase proliferation.
- Review queue UI: not yet built. Candidate merges currently auto-merge (with conservative validator). Recommend adding a manual review queue before relaxing merge thresholds.
- Implicit feedback detectors: not implemented. Only explicit `Mark helpful` and assistant logging exist.

Verification checklist (Lumi-specific)

1) Confirm GLB persona is visible and no SVG is shown.
2) Interact with assistant, click `Mark helpful`, then confirm `training/training.jsonl` and `training/lumi_knowledge.json` updated.
3) From renderer console, call `window.lumi.getMetrics()` and verify returned counts.

Next Lumi-focused tasks (priority)

1. Implement embedding-based dedupe + `merged_from` metadata (high priority).
2. Add a human review queue UI and hold merges in staging by default until curator accepts (medium-high priority).
3. Add implicit-feedback detectors and heuristics for auto-flagging likely-accepted replies (low-medium priority).

End of Lumi log for 2026-01-25.

```
